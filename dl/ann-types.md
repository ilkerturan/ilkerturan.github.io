#  Yapay Sinir A覺 T羹rleri

Yapay Sinir Alar覺 (YSA), veriyi ileme y繹ntemlerine ve 繹renme kapasitelerine g繹re d繹rt ana kategoride incelenir.

## 1. Temel Alar: 襤leri Beslemeli Sinir Alar覺 (FNN)

襤leri Beslemeli Alar, bilginin tek bir y繹nde, girdiden balayarak dorudan 癟覺kt覺ya doru hareket ettii en temel YSA yap覺s覺d覺r.

### ok Katmanl覺 Alg覺lay覺c覺 (Multi-Layer Perceptron - MLP)

MLP, bir **Giri Katman覺**, bir veya daha fazla **Gizli Katman** ve bir **覺k覺 Katman覺** i癟eren standart ileri beslemeli mimaridir. Adaki n繹ronlar katmanlar aras覺nda **tam balant覺l覺d覺r**. Bu a覺n en kritik 繹zellii, gizli katmanlar覺nda yer alan **dorusal olmayan (non-linear)** aktivasyon fonksiyonlar覺 sayesinde verideki karma覺k ve erisel ilikileri 繹renebilmesidir. Eitim, **Geri Yay覺l覺m (Backpropagation)** algoritmas覺 ile yap覺l覺r.

MLP'nin kilit 繹zellii, **haf覺zas覺z** 癟al覺mas覺d覺r; yani her girdi 繹rneini (veri noktas覺n覺) izole ve 繹nceki girdilerden ba覺ms覺z olarak iler. MLP, genel ama癟l覺 **s覺n覺fland覺rma** (kedi/k繹pek ay覺rma) ve **regresyon** (fiyat tahmin etme) problemlerinde kullan覺l覺r.

---

## 2. Haf覺zal覺 Alar: Tekrarlayan Sinir Alar覺 (RNN)

Tekrarlayan Sinir Alar覺, **s覺ral覺 veriler** (metin, ses, zaman serisi) i癟in tasarlanm覺t覺r. Bu alar, dahili bir d繹ng羹 kullanarak **ge癟mi bilgiyi (haf覺zay覺)** bir sonraki karar覺na dahil edebilir.

### Uzun K覺sa S羹reli Bellek (Long Short-Term Memory - LSTM)

Temel RNN'lerin uzun s覺ral覺 verilerde yaad覺覺 **Kaybolan Gradyan** sorununu 癟繹zmek i癟in gelitirilmilerdir. LSTM'ler, standart bir n繹ron yerine bilgiyi kontrol eden 繹zel bir h羹cre yap覺s覺 kullan覺r. Bu h羹crenin i癟inde **Kap覺lar (Gates)** bulunur:

1.  **Unutma Kap覺s覺:** H羹cre durumundaki hangi bilginin at覺lmas覺 gerektiini belirler.
2.  **Giri Kap覺s覺:** Hangi yeni bilginin h羹cre durumuna eklenmesi gerektiini belirler.
3.  **覺k覺 Kap覺s覺:** H羹credeki bilginin hangi k覺sm覺n覺n o andaki 癟覺kt覺 olarak kullan覺laca覺n覺 belirler.

Bu karma覺k kontrol mekanizmas覺 sayesinde LSTM'ler, balamsal ve **uzun s羹reli ba覺ml覺l覺k** gerektiren **Makine evirisi** ve **Konuma Tan覺ma** gibi g繹revlerde 羹st羹n baar覺 g繹sterir.

---

## 3. Uzamsal Alar: Evriimli Sinir Alar覺 (CNN)

Evriimli Sinir Alar覺, 繹zellikle **g繹r羹nt羹 ve video** gibi uzamsal hiyerari i癟eren verileri ilemek i癟in tasarlanm覺t覺r.

CNN'in mimarisi, ard覺覺k **Evriim (Convolution)** ve **Havuzlama (Pooling)** katmanlar覺ndan oluur.

* **Evriim Katman覺:** G繹r羹nt羹 羹zerinde k羹癟羹k bir matris olan **filtreler (癟ekirdekler)** gezdirilir. Bu filtreler, g繹r羹nt羹deki kenar, k繹e veya doku gibi **yerel 繹zellikleri** 癟覺kar覺r. **A覺rl覺k Payla覺m覺** prensibi sayesinde, bir filtre g繹r羹nt羹n羹n tamam覺n覺 tarar; bu da parametre say覺s覺n覺 b羹y羹k 繹l癟羹de azalt覺r.
* **Havuzlama Katman覺:** Evriimden 癟覺kan 繹zellik haritas覺n覺n boyutunu k羹癟羹lterek (genellikle maksimum deeri se癟erek), a覺n **konumdan ba覺ms覺z** (g繹r羹nt羹n羹n neresinde olursa olsun) 繹zellikleri tan覺mas覺n覺 salar ve hesaplama y羹k羹n羹 hafifletir.

CNN'ler, **G繹r羹nt羹 S覺n覺fland覺rma**, **Nesne Tespiti** ve otonom ara癟lar gibi g繹rsel analiz gerektiren alanlar覺n temelini oluturur.

---

## 4. retken Alar (Generative Adversarial Networks - GAN)

retken ekimeli Alar, mevcut bir veri k羹mesinin da覺l覺m覺n覺 繹renerek, o veri k羹mesine ait **yeni ve ger癟ek癟i** 繹rnekler 羹retir.

GAN'lar, birbirine kar覺 rekabet eden iki sinir a覺ndan oluur:

1.  **retici (Generator):** S覺f覺rdan, ger癟ek癟i g繹r羹nmeye 癟al覺an sahte veri 繹rnekleri (繹rnein fotoraflar) 羹retir.
2.  **Ay覺rt Edici (Discriminator):** Hem ger癟ek veri 繹rneklerini hem de retici'den gelen sahte 繹rnekleri girdi olarak al覺r ve hangisinin ger癟ek, hangisinin sahte olduuna karar vermeye 癟al覺覺r.

襤ki a覺n bu **Min-Max Oyunu** (癟ekimesi), retici'yi o kadar yetenekli hale getirir ki, 羹rettii 癟覺kt覺lar ger癟einden ay覺rt edilemez. GAN'lar, y羹ksek kaliteli **yapay g繹r羹nt羹 oluturma** (Deepfake) ve **sentetik veri 羹retimi** gibi g繹revlerde kullan覺l覺r. Ancak eitilmeleri zordur ve **Mod 繹kmesi (Mode Collapse)** riski ta覺rlar.

---

## S繹zl羹k (Glosary)

* **Aktivasyon Fonksiyonu:** Bir n繹rondan 癟覺kan sinyalin g羹c羹n羹 belirleyen ve aa **dorusal olmayan** yetenek katan matematiksel fonksiyondur (rn: ReLU, Sigmoid).
* **A覺rl覺k Payla覺m覺 (Weight Sharing):** CNN'lerde kullan覺lan bir tekniktir. Ayn覺 filtrenin t羹m girdi g繹r羹nt羹s羹 羹zerinde kullan覺lmas覺d覺r. Bu, 繹renilen parametre (a覺rl覺k) say覺s覺n覺 繹nemli 繹l癟羹de azalt覺r.
* **Backpropagation (Geri Yay覺l覺m):** Bir sinir a覺n覺 eitmek i癟in kullan覺lan ana algoritmad覺r. A覺n 癟覺kt覺s覺 ile istenen 癟覺kt覺 aras覺ndaki hatay覺 (kayb覺) hesaplar ve bu hatay覺 a覺n en arkas覺ndan 繹ne doru yayarak a覺rl覺klar覺 g羹nceller.
* **Evriim (Convolution):** CNN'lerde temel ilem birimidir. Bir filtrenin (癟ekirdein) girdi g繹r羹nt羹s羹 羹zerinde kayd覺r覺larak yerel 繹zellikleri 癟覺karmas覺 ilemidir.
* **Haf覺zas覺z (Memoryless):** Bir sistemin veya a覺n, karar覺n覺 sadece o anki girdiye dayand覺rmas覺 ve 繹nceki girdileri/癟覺kt覺lar覺 hat覺rlamamas覺 durumudur (MLP'ler i癟in ge癟erlidir).
* **Kaybolan Gradyan (Vanishing Gradient):** Derin sinir alar覺nda, 繹zellikle temel RNN'lerde, geri yay覺l覺m s覺ras覺nda hatan覺n (gradyan覺n) geriye doru gittik癟e k羹癟羹lmesi ve kaybolmas覺 sorunudur. Bu durum, a覺n bataki katmanlardaki a覺rl覺klar覺 g羹ncelleyememesine neden olur.
* **Regresyon:** Makine 繹reniminde s羹rekli bir say覺sal deer tahmin etme g繹revidir (rn: Ev fiyat覺, s覺cakl覺k tahmini).
* **S覺n覺fland覺rma:** Makine 繹reniminde bir veri noktas覺n覺 belirli bir kategoriye (s覺n覺fa) atama g繹revidir (rn: Bir g繹r羹nt羹n羹n "kedi" veya "k繹pek" olmas覺).
* **Uzun S羹reli Ba覺ml覺l覺k (Long-Term Dependency):** Bir dizideki (metin, zaman serisi) karar vermek i癟in dizinin 癟ok ba覺ndaki bir bilgiye ihtiya癟 duyma durumudur (LSTM'lerin temel 癟繹zd羹羹 sorun).
